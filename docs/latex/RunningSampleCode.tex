\chapter{Running the Sample Code}

Sample code is provided alongside this document to demonstrate the implementation of a shared object feed handler that
communicates with a background thread in C. It has been written to run on Linux and Windows using the CMake\footnote{http://www.cmake.org/}
build tool. It has been tested with version \textbf{3.2}, but there should be no issues running the examples with any
version \textbf{3.x} of kdb+. It should be noted that this code is not production ready as much of the required error
handling has been omitted in order to make the code clear.

\section{Building the Sample Code}

You can download the example code from the \href{http://www.aquaq.co.uk/resource}{AquaQ Resources} section of the website
and extract it to a directory on your. Building on all platforms is initially handled with the CMake build tool (version 2.6+
is required) which will in turn generate the platform specific build files.

After extracting the zip file, the directory structure should something look like the one below. The \textbf{src} directory
contains the source code for the project and the \textbf{CMakeLists.txt} file contains the build instructions for CMake.

\begin{figure}
\begin{lstlisting}
src/				-- contains the source code for the project
CMakeLists.txt		-- contains instructions on how to build
\end{lstlisting}
\caption{Contents of the downloaded zip file}
\end{figure}

The next step is to create a \textbf{build/} directory, switch to that directory and then run \verb|cmake ..|. This will output
Makefiles on Linux and Visual Studio solutions on Windows.

\subsection{Building on Linux}

To finish the build on Linux, run \verb|make install| in order to build all of the binaries. The resulting binaries will be placed
in the \textbf{<build directory>/../bin} folder.

\begin{figure}
\begin{lstlisting}
aquaq:~/fakefeed> mkdir build
aquaq:~/fakefeed> ls
/home/aquaq/fakefeed
total 16K
drwxr-xr-x 3 4.0K Mar 30 16:25 build/
drwxr-xr-x 2 4.0K Mar 27 13:34 src/
-rw-r--r-- 1  961 Mar 27 13:56 CMakeLists.txt
aquaq:~/fakefeed> cd build
aquaq:~/fakefeed/build> cmake .. && make install
\end{lstlisting}
\caption{Building the project on Linux using Makefiles}
\end{figure}

\subsection{Building on Windows}

On Windows, you can either open the Visual Studio solution called \verb|fakefeed.sln| and run the \verb|ALL_BUILD| and \verb|INSTALL|
targets. This will place the binaries in the \textbf{<build directory>/../bin} folder. It is also possible to run these steps manually
from the command line using the \textbf{msbuild} tool. The msbuild tool will typically not be on your PATH after install visual studio,
but a script is provided in \verb|C:\Program Files (x86)\Microsoft Visual Studio\<version>\VC| called \verb|vsvarsall.bat|. This will
place all the required tools on your PATH automatically for the duration of command line session.

\begin{figure}
\begin{lstlisting}
PS C:/Users/AquaQ/FeedHandler> mkdir build
PS C:/Users/AquaQ/FeedHandler/build> cd build
PS C:/Users/AquaQ/FeedHandler/build> msbuild ./ALL_BUILD.vcxproj /p:Configuration=Release
PS C:/Users/AquaQ/FeedHandler/build> msbuild ./INSTALL.vcxproj /p:Configuration=Release
\end{lstlisting}
\caption{Building the Visual Studio projects from the command line}
\end{figure}

\section{Running the Sample Code}

Successful execution of the build script should create a \textbf{bin} folder with the following contents:

\begin{lstlisting}
	bin/
		feedhandler.so
		fakefeed.so
		run.sh
		run.q
\end{lstlisting}

The feedhandler.so file provides the feed handler implementation that will be loaded into the q session using the
dynamic load (\textbf{2:}) operator. It requires that the fakefeed library is in the same directory to generate
trades and quotes before it can send them to kdb+.

The run.q script loads in the functions from the feed handler library and provides the example implementation
of .u.upd. This will by default just print out the data that was received to stdout.
This script should not be run directly on Linux, but instead launched via \verb|./run.sh|. This will ensure
that the \textit{LD\_LIBRARY\_PATH} environment variable has been set correctly. If you want to run
the code without the script, you need to either update your environment variables appropriately, put
the libraries on your PATH or place them in the same folder as your q executable. On Windows, the script should
just be run directly (i.e.\verb|q run.q|) as it looks in the same directory for shared libraries.

Upon running the ./run.sh script, you will be dropped into a q session with the library already loaded.
There will also be definitions of two tables, \textit{quote} and \textit{trade} that will hold the data 
while the feed handler is running.  You should be able to see three functions: \textit{init}, \textit{halt} and
\textit{.u.upd}. Running the init function will start the feed handler and allows it to generate random trade and
quote data using the fake feed library. The .u.upd function will be called once for each update (which could be
either a single update or a batch of messages).

\begin{figure}
\begin{lstlisting}
$ /home/aquaq/fakefeed/bin> ./run.sh
KDB+ 3.2 2014.10.04 Copyright (C) 1993-2014 Kx Systems
l64/ 16()core 24145MB mrooney homer 127.0.0.2 EXPIRE 2015.04.01 aquaq.co.uk #46218

q)trade
time sym exg size volume sequence price cond
--------------------------------------------
q)quote
time sym exg asksize bidsize askprice bidprice sequence cond
------------------------------------------------------------
q)init
code
q).u.upd
{[t;x] t insert raze .z.p,x; }
\end{lstlisting}
\caption{Starting the script on Linux and examining the tables/functions}
\end{figure}

You can then start the feed handler by running the \verb|init| function which will cause quotes and trades to start
appearing in their respective tables. You can run the halt function to stop the feed handler, however this will
not clear the current table data in the q process.

\begin{figure}
\begin{lstlisting}
q)init[]
q)count trade
22411
q)count quote
467599
q)halt[]
q)10#trade
time                          sym  exg  size volume sequence price cond                  
-----------------------------------------------------------------------------
2015.03.30D15:29:51.186145000 GOOG BARK 334  990    102596   182.9 0x20494946
2015.03.30D15:29:51.186312000 GOOG CME  328  11     82843    417.3 0x49202043
2015.03.30D15:29:51.186514000 APPL BARK 360  739    37111    298.9 0x43432046
2015.03.30D15:29:51.186819000 MSFT CME  324  341    92989    177   0x4043205a
2015.03.30D15:29:51.186834000 APPL LSE  218  561    4307     381   0x20494043
2015.03.30D15:29:51.186863000 GOOG BARK 340  607    154825   197.7 0x4340435a
2015.03.30D15:29:51.187741000 IBM  CME  18   255    32858    201.1 0x46494349
2015.03.30D15:29:51.187848000 MSFT LSE  169  829    65794    413.8 0x205a4946
2015.03.30D15:29:51.187899000 YHOO BARK 285  864    185921   494.3 0x5a49495a
2015.03.30D15:29:51.188097000 IBM  LSE  401  380    101563   304.3 0x20494920
\end{lstlisting}
\caption{Starting and stopping the feed handler and viewing the received trades \& quotes}
\end{figure}

To stop the feed handler, just run the halt function which will cause the feed handler to stop all the background threads and release all unused memory that it had allocated.

\section{Integration with the Starter Pack}

If you have set up \textbf{TorQ} and accompanying \textbf{Financial Starter Pack}, it is possible
to use the example feed handler as one of your data sources. To do this, you will need to copy over the binaries, modify the schema file and then integrate the feed handler into \verb|tickerplant.q|.

The basic directory layout of your TorQ installation should look similar to the example below. The \verb|start_torq_demo.sh| script should start up several services including a ticker plant, rdb and hdb.

\begin{figure}[h]
\begin{lstlisting}
aquaq:~/torq/TorQ> ls
/home/aquaq/torq/TorQ
total 104K
drwxr-xr-x 7 4.0K Mar 24 11:41 code/
drwxr-xr-x 5 4.0K Mar 24 11:41 config/
drwxr-xr-x 3 4.0K Mar 30 14:44 hdb/
drwxr-xr-x 5 4.0K Mar 24 11:41 html/
drwxr-xr-x 7 4.0K Mar 24 11:41 lib/
drwxr-xr-x 2  12K Mar 30 15:58 logs/
drwxr-xr-x 2 4.0K Mar 17 13:10 tick/
-rw-r--r-- 1  210 Mar 30 14:50 tickerplant.q
-rw-r--r-- 1 2.5K Mar 17 13:10 tick.q
-rw-r--r-- 1  20K Mar 24 11:41 torq.q
-rw-r--r-- 1  557 Mar 30 15:46 setenv.sh
-rwxr-xr-x 1 2.1K Mar 30 15:41 start_torq_demo.sh*
-rwxr-xr-x 1  284 Mar 30 14:45 stop_torq_demo.sh*
-rwxr-xr-x 1 8.5K Mar 30 15:39 fakefeed.so*
-rwxr-xr-x 1  14K Mar 30 15:39 feedhandler.so*
\end{lstlisting}
\caption{Directory layout for the base TorQ install}
\end{figure}

\subsection{Installing the libraries}

The libraries should be placed into the lib directory and in the appropriate subdirectory depending on the platform that you are using. For example if you have compiled the libraries on
Windows for 32-bit processes, you should place them in the \verb|lib/w32| directory.

\begin{figure}[h]
\begin{lstlisting}
mrooney@homer:~/torq/TorQ> ls lib/l32
/home/mrooney/torq/TorQ
total 436K
-rwxr-xr-x 1 375K Mar 24 11:41 libcurl.so.4*
-rwxr-xr-x 1 8.5K Mar 30 15:39 fakefeed.so*
-rwxr-xr-x 1  14K Mar 30 15:39 feedhandler.so*
-rwxr-xr-x 1  31K Mar 24 11:41 torQemail.so*
\end{lstlisting}
\caption{Placing the \textit{fakefeed.so} and \textit{feedhandler.so} file into the correct location for 32-bit Linux binaries}
\end{figure}

Depending on your system, you may also need set environment variables to allow the libraries to be loaded. For Linux, we need to set the
\textbf{LD\_LIBRARY\_PATH} to point to the appropriate lib directory. Within TorQ, the best place to set this is in the \textbf{setenv.sh}
script that is located in the root directory.

\begin{figure}[h]
\begin{lstlisting}
# Setting LD_LIBRARY_PATH on a 32-bit Linux system:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$KDBLIB/l32

# Similar line that would be used on OSX:
# 	export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:$KDBLIB/m32
\end{lstlisting}
\caption{}
\end{figure}

This also means that you can just load the library by providing its name rather than its path.

\subsection{Modifying the Schema}

In order to change the schema, we need to modify the \verb|database.q| file that is located in the
\verb|tick/| directory. We will add two new tables -- \verb|trade| and \verb|quote| -- to this file.

\begin{figure}[h]
\begin{lstlisting}
trade:([]time:`timestamp$(); sym:`g#`symbol$(); exg:`symbol$(); size:(); volume:();
			sequence:(); price:(); cond:());
quote:([]time:`timestamp$(); sym:`g#`symbol$(); exg:`symbol$(); asksize:(); bidsize:();
			askprice:(); bidprice:(); sequence:(); cond:());
\end{lstlisting}
\caption{The trade and quote schemas defined in \textit{tick/database.q}}
\end{figure}

Note that you will need to restart the processes in order for this change to take effect. To confirm that the schemas are visible, connect to the \textbf{tickerplant} or \textbf{rdb} and manually inspect the visible tables.

\subsection{Updating tickerplant.q}

The \textbf{tickerplant.q} script can be found in the root directory of the TorQ installation. It is a simple wrapper that helps load the default tick.q script from Kx into TorQ. We will use the dynamic load function (\textbf{2:}) to load the libraries from their location in the library folder, and then call the \textbf{init}
function to start the feed handler in the background. It should then repeatedly call the .u.upd function in the
feed handler.

\begin{figure}[h]
\begin{lstlisting}
/- Example script to launch a tickerplant
/- requires kdb+tick (tick.q and tick directory) to be in the current directory
\l tick.q
\l torq.q

/- We can load the feed handler by importing the init/halt functions and then
/- immediately calling init in order to start processing updates.
init:`:./feedhandler 2:(`init;1)
halt:`:./feedhandler 2:(`halt;1)
init[]
\end{lstlisting}
\caption{The updated \textit{tickerplant.q} script that starts the feed handler}
\end{figure}

\subsection{Checking the Results}

If you restart the processes, you should now notice that the trade and quote tables are being populated correctly
by the fake feed handler. As the tickerplant and the feed handler are both part of the same process, there should
be very little latency between the messages being parsed and then published to any subscribers.

\begin{figure}[h]
\begin{lstlisting}
q) h:hopen 7001
q) h"tables[]"
`quote`trade
q) h"count quote"
4372876
\end{lstlisting}
\caption{}
\end{figure}